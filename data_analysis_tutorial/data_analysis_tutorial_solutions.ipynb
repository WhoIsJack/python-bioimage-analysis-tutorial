{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream Analysis of Single-Cell Data  -- <font color='orange'>Solutions</font>\n",
    "\n",
    "<br><font color='red'>**Warning 1:** These materials were put together relatively quickly and have not been thoroughly double-checked and optimized yet! Any feedback that may help to improve these materials is very welcome! </font><br><br>\n",
    "\n",
    "<font color='red'>**Warning 2:** These materials use an example image with a quite uniform population of cells (meaning the cells are in general quite similar). As a consequence, there aren't really any interesting patterns that can be uncovered by data analysis, which is a bit unfortunate for a tutorial on this topic. However, the concepts can still be explained - it's just that the outcome won't be too exciting. We are planning to switch to more interesting example images in the future.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory Notes\n",
    "\n",
    "\n",
    "### About this Tutorial\n",
    "\n",
    "This tutorial provides an introductory overview of how to approach single-cell analysis following image segmentation.  \n",
    "\n",
    "For people with limited experience in data analysis, this tutorial is intended as an inspiration and incentive to think about possible advanced analyses downstream of segmentation. Solving the exercises without help may be difficult, so it may be a good idea to have a look at the solutions to get some idea of how the problems should be approached. However, once the principles are understood, it is an important part of the learning experience to build your own implementation and to play around with different possibilities.\n",
    "\n",
    "People more experienced in data science can use this tutorial as a starting point for exploring the data analysis packages available in Python. It also illustrates that Python readily allows the construction of complete and consistent analysis pipelines, from image preprocessing to feature extraction to clustering. \n",
    "\n",
    "\n",
    "### Concepts Discussed in this Tutorial\n",
    "\n",
    "- Feature extraction\n",
    "    - Specific features of interest\n",
    "    - General image descriptors\n",
    "\n",
    "\n",
    "- Feature space standardization\n",
    "\n",
    "\n",
    "- Dimensionality reduction\n",
    "    - PCA\n",
    "    - tSNE\n",
    "\n",
    "\n",
    "- Clustering by k-means (including Elbow plots)\n",
    "\n",
    "\n",
    "- Graph/network-based data representation and visualization\n",
    "\n",
    "\n",
    "\n",
    "### Data Analysis with Python\n",
    "\n",
    "There are a number of data analysis, machine learning, clustering and other data analysis packages for Python. The following is a list of some commonly used packages:\n",
    "\n",
    "- [`pandas`](http://pandas.pydata.org/)\n",
    "    - Provides a dataframe object ideal for handling `sample x feature` data\n",
    "    - Most of the packages mentioned below can seamlessly work with `pandas` dataframes\n",
    "    - *Note:* the solutions to this tutorial currently do *not* use `pandas` *but will be updated to do so in the future!*\n",
    "\n",
    "\n",
    "- [scikit-learn (`sklearn`)](http://scikit-learn.org/stable/)\n",
    "    - Large data analysis and machine learning package featuring many standard and state-of-the-art algorithms\n",
    "\n",
    "\n",
    "- [`scipy.cluster`](http://docs.scipy.org/doc/scipy/reference/cluster.html)\n",
    "    - Scipy implementation of clustering algorithms\n",
    "\n",
    "\n",
    "- [`networkx`](http://networkx.github.io/)\n",
    "    - Package for graph-based analysis and visualization of data\n",
    "\n",
    "\n",
    "- [`keras`](https://keras.io/)\n",
    "    - Extensive state-of-the-art package for deep learning\n",
    "    - Provides APIs for Theano and TensorFlow\n",
    "    - *Note:* this tutorial currently does *not* cover deep learning\n",
    "    \n",
    "\n",
    "- [`pyMC`](https://pymc-devs.github.io/pymc/)\n",
    "    - Package for Bayesian modeling and Markov-Chain Monte-Carlo sampling\n",
    "    - *Note:* this tutorial currently does *not* cover Bayesian inference\n",
    "\n",
    "Most of these packages use `numpy` arrays (or `pandas` dataframes) to handle data, so being familiar with `numpy` is an essential prerequisite to working with any of the above. If you have completed the main tutorial, you should not have any major problems with this.\n",
    "\n",
    "\n",
    "### Setup\n",
    "\n",
    "The following packages/modules need to be installed for this tutorial. With the exception of `tifffile`, they should all come pre-installed with the Anaconda distribution or sould be easy to install using `conda install` or `pip install`.\n",
    "\n",
    "- **Already needed for main tutorial**\n",
    "    - python 2.7 *(or python 3.x, if you don't mind adjusting the solutions)*\n",
    "    - `numpy`\n",
    "    - scikit-image (`skimage`)\n",
    "    - `matplotlib`\n",
    "    - `scipy`\n",
    "    - `tifffile`\n",
    "\n",
    "\n",
    "- **New for this tutorial**\n",
    "    - scikit-learn  (`sklearn`)\n",
    "    - `networkx`\n",
    "\n",
    "Make sure these modules are installed before you proceed.\n",
    "\n",
    "Note that this tutorial is based on the segmentation and extracted measures from `example_image_1.tif` from the main pipeline. The necessary files to run the solutions are included in this directory, but it might be a bit more interesting for you to use the results of your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing modules\n",
    "\n",
    "from __future__ import division    # Python 2.7 legacy (not necessary if working with python v3.x)\n",
    "import numpy as np                 # Array manipulation package\n",
    "import matplotlib.pyplot as plt    # Plotting package\n",
    "import scipy.ndimage as ndi        # Multidimensional image operations\n",
    "\n",
    "import sklearn as skl              # Data analysis and machine learning\n",
    "import networkx as nx              # Graphs/networks\n",
    "\n",
    "import json                        # File handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 0  (Solution)</font>\n",
    "\n",
    "Reload the image, the segmentation, and the results dictionary from the main tutorial. The labeled cell edges may also be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading image and segmentation data from the main tutorial\n",
    "\n",
    "# Filename\n",
    "filename = 'example_cells_1.tif'\n",
    "\n",
    "# Load the image\n",
    "from tifffile import imread\n",
    "img = imread(filename)\n",
    "img_green = img[0,:,:]\n",
    "img_red   = img[1,:,:]\n",
    "\n",
    "# Load the cell edges\n",
    "edges = imread(filename[:-4]+'_edges.tif')\n",
    "\n",
    "# Load the segmentation\n",
    "seg = np.load(filename[:-4]+'_seg.npy')\n",
    "\n",
    "# Load the results dictionary\n",
    "with open(filename[:-4]+'_results.json', 'r') as infile:\n",
    "    res = json.load(infile)\n",
    "\n",
    "# Some frequently used variables\n",
    "labels = np.unique(seg)[1:]  # Labels of cells in segmentation\n",
    "N = len(labels)              # Number of cells in segmentation\n",
    "\n",
    "# Report\n",
    "print \"Loaded file\", filename\n",
    "print \"  Number of cells:   \", N\n",
    "print \"  Number of features:\", len(res)-1\n",
    "\n",
    "# SOLUTION NOTE: If you're working through these tutorials in a Jupyter Notebook, you could\n",
    "#                also use the Jupyter magic %store command to share the variables between\n",
    "#                your main tutorial notebook and this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "As discussed in the main tutorial, we can measure various quantities for each cell individually (once the cells have been segmented). These quantities can be considered 'features' for the purpose of further analysis such as clustering. Besides explicitly measured specific quantities, there are also algorithms that automatically extract a whole bunch of features from an image.\n",
    "\n",
    "All the extracted features together are called the 'feature space'. Each sample can be considered a point in feature space, which has as many dimensions as there are features. The feature space should be arranged as an array of shape `(n_samples,n_features)` or in an equivalent pandas `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 1  (Solution)</font>\n",
    "\n",
    "You should already have a set of single-cell measurements ('features') from the main tutorials, stored in the results dict.\n",
    "\n",
    "Try to think of a few (at least 2) additional features and extract them from the image/segmentation. Be creative and try to find features that might contain biologically interesting information!\n",
    "\n",
    "Combine all the features in a 'feature_space' array of shape `(n_samples,n_features)`, where `n_samples` in our case is the number of cells. You could also use a pandas dataframe for this. Be sure to use a data type that works for all the different types of features you are using. If you are using numpy arrays, it makes sense to also keep a list of column labels (names of the features) and row labels (cell IDs) because the array itself is unlabeled.\n",
    "\n",
    "- **Hint 1:** For many measures of shape and spatial distribution, it is useful to first calculate the `centroid` of the segmented object and then think of features relative to it.\n",
    "\n",
    "\n",
    "- **Hint 2:** It can be advantageous to use measures that are largely independent of cell size (or normalized for cell size) to prevent cell size from dominating the different features. Of course, cell size itself should be a feature.\n",
    "\n",
    "\n",
    "- **Hint 3:** Don't forget that we also identified the boundaries of each cell in the main script. Importing or reconstructing this data here may be useful for the calculation of various features.\n",
    "\n",
    "\n",
    "- **Hint 4:** Make sure you visualize your data!\n",
    "    - It can be very useful to have a look at what a feature looks like when mapped to the actual image (using a semi-transparent overlay, see section 'Expansion by Watershed' in the main tutorial). \n",
    "    - This may already show interesting patterns, or should at least confirm that the extracted values are consistent with the feature's rationale.\n",
    "    - Also, box and scatter plots are great options for checking how the values of a feature are distributed and how features relate to each other.\n",
    "    \n",
    "\n",
    "<font color='orange'>**Solution note:**</font> The following are just suggestions/ideas! Your solution should be conceptually similar but not at all the same. This also goes for the rest of the pipeline, both because there are multiple ways of achieving the same or a similar goal, and also because your solutions here will change the outcome of the analyses further below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize feature space array and add previously extracted features\n",
    "\n",
    "# Initialize feature space\n",
    "fspace = np.zeros((N,9),dtype=np.float)\n",
    "\n",
    "# Labels\n",
    "col_labels = []\n",
    "\n",
    "# Useful index to paste things into fspace array\n",
    "col_index  = 0\n",
    "\n",
    "# Add previously extracted measures to feature space\n",
    "for measure in res.keys():\n",
    "    if not measure == 'cell_id':\n",
    "        col_labels.append(measure)\n",
    "        fspace[:,col_index] = res[measure]\n",
    "        col_index += 1\n",
    "\n",
    "print col_labels\n",
    "print fspace.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get additional features and add them to the feature space\n",
    "\n",
    "# Get the centroids\n",
    "cen = np.zeros((N,2))\n",
    "for row_index,label in enumerate(labels):\n",
    "    cen[row_index,:] = ndi.measurements.center_of_mass(seg==label)\n",
    "\n",
    "\n",
    "# FEATURE: Standard deviation of membrane intensity\n",
    "# Depending on the channel used and the sample, a feature like this could relate \n",
    "# to cell polarity, membrane ruffling, protrusions, receptor clustering, \n",
    "# endocytosis, junctions, ...\n",
    "\n",
    "# Iterate over cells\n",
    "for row_index,label in enumerate(labels):\n",
    "    \n",
    "    # Get the membrane standard deviation\n",
    "    fspace[row_index,col_index] = np.std(img_green[edges==label])\n",
    "\n",
    "# Update column label\n",
    "col_labels.append(\"green_mem_stdev\")\n",
    "col_index += 1\n",
    "\n",
    "\n",
    "# FEATURE: Intensity asymmetry as the distance of the intensity-weighted centroid\n",
    "#          from the unweighted centroid.\n",
    "# This feature could be useful to look at cell polarity. \n",
    "\n",
    "# Iterate over cells\n",
    "for row_index,label in enumerate(labels):\n",
    "    \n",
    "    # Intensity-weighted center of mass\n",
    "    int_cen = ndi.measurements.center_of_mass(np.ma.array(img_green,mask=edges!=label))\n",
    "    \n",
    "    # Distance between the two centroids\n",
    "    # Note: Below I use the pairwise distance function pdist from scipy's\n",
    "    #       spatial package. This function is useful for a lot of things in\n",
    "    #       data analsis, but to be more explicit one could also calculate the\n",
    "    #       distance between two centroids using simple Pythagoras:\n",
    "    #           diff = int_cen - cen[index,:]\n",
    "    #           dist = np.sqrt(np.square(diff[0]) + np.square(diff[1]))\n",
    "    from scipy.spatial.distance import pdist\n",
    "    fspace[row_index,col_index] = pdist([int_cen,cen[row_index,:]])[0]\n",
    "\n",
    "# Update column label\n",
    "col_labels.append(\"green_asymmetry\")\n",
    "col_index += 1\n",
    "\n",
    "\n",
    "# FEATURE: Roundnes of the cells as the ratio of inscribed vs circumscribed circle\n",
    "# This feature could relate to the forces excerted on a cell or to polarity.\n",
    "# It may also be able to detect the rounding of a cell as it enters division.\n",
    "\n",
    "# Iterate over cells\n",
    "for row_index,label in enumerate(labels):\n",
    "    \n",
    "    # Distance transform to get circular distance around centroid\n",
    "    dtr = np.ones_like(seg)\n",
    "    dtr[int(cen[row_index,0]),int(cen[row_index,1])] = 0\n",
    "    dtr = ndi.distance_transform_edt(dtr)\n",
    "    \n",
    "    # Calculate circle radii and their ratio\n",
    "    in_rad  = np.min(np.ma.array(dtr,mask=seg==label))  # Maximum inscribed circle radius \n",
    "    out_rad = np.max(np.ma.array(dtr,mask=seg!=label))  # Minimum circumscribed circle\n",
    "    fspace[row_index,col_index] = in_rad / out_rad              # Ratio\n",
    "\n",
    "# Update column label\n",
    "col_labels.append(\"roundness\")\n",
    "col_index += 1\n",
    "\n",
    "# Report\n",
    "print col_labels\n",
    "print fspace.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 2  (Solution)</font>\n",
    "\n",
    "Use a feature extraction algorithm that returns a large feature set for each cell; an image **descriptor**. The features could for example be related to shape or texture. Feel free to search around the internet for a bit to see what kind of interesting algorithms are available. The algorithm should produce a second feature space that once again has the shape `(n_samples,n_features)`.\n",
    "\n",
    "The one used in the solutions is `skimage.feature.daisy`, an algorithm for the extraction of local image features based on a grayscale image. It should be pointed out, however, that membrane images are not what [DAISY](scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.daisy) would typically be applied to; it is best used for images with more local patterning/texture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Extraction of DAISY image descriptor features\n",
    "\n",
    "# Initialize feature space\n",
    "fspace2 = np.zeros((N,200))\n",
    "\n",
    "# Get the daisy function\n",
    "from skimage.feature import daisy\n",
    "\n",
    "# Loop over cells\n",
    "for index,label in enumerate(labels):\n",
    "    \n",
    "    # Crop image to bounding box of the cell of interest\n",
    "    # Note: the DAISY image descriptors may be partially sensitive to the size\n",
    "    #       of the image it is being computed from. Thus, cropping the image to\n",
    "    #       bounding boxes of different sizes may not be the ideal strategy here!\n",
    "    non_zero_indices = np.nonzero(seg==label)\n",
    "    y_min = np.min(non_zero_indices[0])\n",
    "    y_max = np.max(non_zero_indices[0])\n",
    "    x_min = np.min(non_zero_indices[1])\n",
    "    x_max = np.max(non_zero_indices[1])\n",
    "    cell_img = img_green[y_min:y_max,x_min:x_max]\n",
    "    \n",
    "    # Extract DAISY features and build a feature space with a subset of them\n",
    "    # Note that some of the segmentation artefacts can cause an error here;\n",
    "    # these cells are marked as NaN (Not a Number) in the feature space and\n",
    "    # will be excluded below. A try-except clause is used to handle the error.\n",
    "    try:\n",
    "        daisy_features = daisy(cell_img, step=2, radius=8)[0]\n",
    "        fspace2[index,:] = daisy_features[0,:]\n",
    "    except Exception:\n",
    "        fspace2[index,:] = np.NaN\n",
    "\n",
    "# Exclusion of cells that produced an error\n",
    "# By deleting them from both the feature space and the list of labels,\n",
    "# the feature space remains mapped onto the segmentation correctly.\n",
    "# Note that the deletion of samples containing outliers or producing errors\n",
    "# is a common step in cleaning up data for advanced analysis. However, one\n",
    "# has to be careful to avoid accidentally introducing bias into the dataset\n",
    "# through these deletions.\n",
    "keep = []\n",
    "for index,label in enumerate(labels):\n",
    "    if not np.isnan(fspace2[index,0]):\n",
    "        keep.append(index)\n",
    "labels2 = labels[keep]\n",
    "fspace2 = fspace2[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 3  (Solution)</font>\n",
    "\n",
    "Just as with the measurements in the main tutorial, it can be interesting to check how the extracted features map onto the actual cells. You can do this with an appropriately colored semi-transparent overlay, just as in the main tutorial.\n",
    "\n",
    "Have a look at your newly constructed features to see if they make sense. You can also have a look at some of the DAISY features.\n",
    "\n",
    "Besides the semi-transparent overlays, the population data we now have available can of course also be visualized and investigated by means of scatter plots and boxplots. Feel free to play around a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature visualizations\n",
    "\n",
    "# Compute image mapping of 'roundness'\n",
    "mapped = np.zeros_like(img_green,dtype=np.float)\n",
    "for row_index,label in enumerate(labels):\n",
    "    mapped[seg==label] = fspace[row_index,col_labels.index('roundness')]\n",
    "    \n",
    "# Transparent overlay\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(img_green,cmap='gray',interpolation='none')\n",
    "plt.imshow(np.ma.array(mapped,mask=mapped==0),interpolation='none',alpha=0.7) \n",
    "plt.show()\n",
    "\n",
    "# Scatterplot of 'cell area' over 'standard deviation of membrane intensity'\n",
    "plt.scatter(fspace[:,col_labels.index('cell_area')],fspace[:,col_labels.index('green_asymmetry')])\n",
    "plt.xlabel(\"cell area [pixels]\")\n",
    "plt.ylabel(\"standard deviation of membrane intensity [a.u.]\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of all the manually extracted features\n",
    "# Note that this looks terrible because of the different scales of the features. \n",
    "# This is addressed in the next section!\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.boxplot(fspace,labels=col_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Standardization\n",
    "\n",
    "Many classification and clustering algorithms need features to be normalized and/or standardized, otherwise the absolute value range of the feature could affect the result (for example, you could get a different result if you use cell size in um or in pixels, because the absolute numbers are different).\n",
    "\n",
    "Normalization in this context generally means scaling your features to a range from 0 to 1. Standardization means centering the features around zero and scaling them to \"unit variance\" by dividing them by their standard deviation (sometimes called \"whitening\").\n",
    "\n",
    "It's worthwhile to read up on normalization/standardization so you can avoid introducing errors/biases. For example, normalization of data with outliers will compress the 'real' data into a very small range. Thus, outliers should\n",
    "be removed before normalization/standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 4  (Solution)</font>\n",
    "\n",
    "In preparation for feature rescaling, find a sensible way to remove outliers from your feature space.\n",
    "\n",
    "Be mindful of implicit assumptions and potential bias that might come with outlier removal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Removing outliers\n",
    "# Simple approach: Compute the standard deviation and consider all values that are more than \n",
    "# 3 sigma from the mean as outliers. \n",
    "# Note: This implicitely assumes a normal distribution of the data, so it may not always be\n",
    "#       a good idea at all!\n",
    "\n",
    "# Find outliers\n",
    "stdevs = np.std(fspace,axis=0)\n",
    "outliers = np.abs(fspace-np.mean(fspace,axis=0)) > 3 * stdevs\n",
    "\n",
    "# Remove outliers (whilst preserving mapping of fspace to labels)\n",
    "keep = np.where(np.sum(outliers,axis=1)==0)[0]\n",
    "labels = labels[keep]\n",
    "fspace = fspace[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 5  (Solution)</font>\n",
    "\n",
    "Standardize or normalize your feature space as you deem fit, either manually or using a module function.\n",
    "\n",
    "Don't forget to visualize the result using a boxplot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center the data around the mean\n",
    "fspace_c = fspace - np.mean(fspace,axis=0) \n",
    "\n",
    "# Whiten\n",
    "from scipy.cluster.vq import whiten\n",
    "fspace_w = whiten(fspace_c)\n",
    "\n",
    "# Same boxplot as above\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.boxplot(fspace_w,labels=col_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "The principal components of a feature space are the axes of greatest variance\n",
    "of the data. By transforming our data to this \"relevance-corrected\" coordinate\n",
    "system, we can achieve two things:\n",
    "\n",
    "1. Usually, most of the variance in a dataset falls onto just a few principal\n",
    "   components, so we can ignore the other ones as irrelevant, thus reducing\n",
    "   the number of features whilst maintaining all or most of the information \n",
    "   in the data ('dimensionality reduction'). For many downstream analyses,\n",
    "   this can improve both the quality of the result and the computational performance.\n",
    "2. Just PCA on its own can yield interesting results. For example, different cell\n",
    "   populations that are not clearly separated by any single feature may \n",
    "   appear separated along a principal component ('clustering'). Furthermore, principal \n",
    "   components may correlate with features of the data, which helps us understand the impact\n",
    "   these features have on downstream analyses. It can also help us understand how abstract\n",
    "   features such as the DAISY descriptors relate to the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 6  (Solution)</font>\n",
    "\n",
    "Perform a PCA on your feature space and investigate the results.\n",
    "\n",
    "You may want to use the PCA implementation of scikit-learn. Algorithms in `sklearn` are provided as \"estimator objects\". The general workflow for using them is as follows:\n",
    "\n",
    "1. Instantiate the estimator object and pass it general parameters.\n",
    "2. Fit the estimator to your data.\n",
    "3. (Optional: extract information about your data from the estimator.)\n",
    "4. Transform your data to the reference space of the estimator.\n",
    "5. (Optional: discard some dimensions of the transformed data, e.g. the dimensions that explain very little of the populations variance in a PCA. This can also be done from the start, by telling the estimator to reduce the data to a set number of dimensions.)\n",
    "\n",
    "Investigate the results of your PCA using scatter plots (and other visualizations if you like):\n",
    "\n",
    "- Plot PCs against each other (PC1 vs PC2, ...)\n",
    "- Plot PCs against features (PC1 vs feature1, feature 2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performing PCA with scikit-learn\n",
    "\n",
    "# Instantiate the estimator object\n",
    "from sklearn.decomposition import PCA\n",
    "pca_estimator = PCA()\n",
    "\n",
    "# Fit the ddata\n",
    "pca_estimator.fit(fspace_w)\n",
    "\n",
    "# Get useful information: percent of variance explained by each principal component\n",
    "print \"PC-explained variance:\", pca_estimator.explained_variance_ratio_\n",
    "\n",
    "# Transform data to principal component space\n",
    "fspace_pca = pca_estimator.transform(fspace_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizing the outcome of the PCA\n",
    "\n",
    "# Scatterplot of PC1 vs PC2\n",
    "# NoTEÃ© Uniform data like this yields a rather diffuse cloud,\n",
    "# whereas more structured data would yield clusters or trajectories.\n",
    "\n",
    "plt.scatter(fspace_pca[:,0],fspace_pca[:,1])\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "# Scatterplots of PC1 vs selected features\n",
    "# Note: If a PC correlates with one or more features, we may\n",
    "# start to get an understanding of the kind of variation that \n",
    "# is represented by that PC.\n",
    "\n",
    "fig,ax = plt.subplots(2,2)\n",
    "\n",
    "ax[0,0].scatter(fspace_w[:,col_labels.index('cell_area')],fspace_pca[:,0])\n",
    "ax[0,0].set_title(\"PC1 vs cell_area\")\n",
    "\n",
    "ax[0,1].scatter(fspace_w[:,col_labels.index('roundness')],fspace_pca[:,0]) \n",
    "ax[0,1].set_title(\"PC1 vs roundness\")\n",
    "\n",
    "ax[1,0].scatter(fspace_w[:,col_labels.index('green_asymmetry')],fspace_pca[:,0]) \n",
    "ax[1,0].set_title(\"PC1 vs green_asymmetry\")\n",
    "\n",
    "ax[1,1].scatter(fspace_w[:,col_labels.index('green_mem_stdev')],fspace_pca[:,0])\n",
    "ax[1,1].set_title(\"PC1 vs green_mem_stdev\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering\n",
    "\n",
    "If you expect that you can split your population into distinct groups, an easy way of doing so in an unsupervised fashion is k-means clustering. K-means partitions samples into clusters based on their proximity to the cluster's centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Exercise 7 (Solution)</font>\n",
    "\n",
    "Perform k-means clustering on your data. You can use `sklearn` or `scipy` to do so.\n",
    "\n",
    "To do so, you have to decide the number of clusters from the start. Just try it with 5 clusters to begin with. You can try clustering raw, normalized/standardized and/or PCA-transformed data to see if there is a difference.\n",
    "\n",
    "Note that we can't really hope for a clear separation of our population into meaningful clusters because our population of cells is very uniform to begin with.\n",
    "\n",
    "Visualize your results as color-coded scatterplots and as a semi-transparent map to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### K-means clustering using scipy\n",
    "\n",
    "# Perform the clustering\n",
    "k = 5\n",
    "import scipy.cluster.vq as svq\n",
    "k_centroids,k_labels = svq.kmeans2(fspace_pca,k)\n",
    "\n",
    "# Visualization in PC space\n",
    "plt.scatter(fspace_pca[:,0],fspace_pca[:,1],c=k_labels,s=30,edgecolor='none') # Color coded data\n",
    "plt.scatter(k_centroids[:,0],k_centroids[:,1],s=150,c=range(k),marker='*') # Centroids\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "# Semi-transparent overlay on the image: mapping\n",
    "mapped = np.zeros_like(img_green,dtype=np.float)\n",
    "for index,label in enumerate(labels):\n",
    "    mapped[seg==label] = k_labels[index] + 1\n",
    "\n",
    "# Semi-transparent overlay on the image: plotting\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(img_green,cmap='gray',interpolation='none')\n",
    "plt.imshow(np.ma.array(mapped,mask=mapped==0),interpolation='none',alpha=0.7) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Bonus Exercise (Solution)</font>\n",
    "\n",
    "Can you find/implement a way of objectively choosing the number of clusters for k-means?\n",
    "\n",
    "<font color='red'>**Warning:**</font> The solution below is probably correct insofar as it uses an Elbow plot, but the computation of the standard deviations is too elaborate and possibly wrong. This will be corrected in a later revision of this tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choosing the number of clusters using an \"Elbow Plot\"\n",
    "# Assuming that we would like to minimize the intra-cluster standard deviation with\n",
    "# as few clusters as possible, we can plot the resulting stdev for different numbers \n",
    "# of clusters and choose the number above which the reduction in the stdev for\n",
    "# additional clusters is marginal.\n",
    "\n",
    "# Package the PCA into a function, together with the extraction of the stdev\n",
    "def pca_stdev(data,k):\n",
    "    \n",
    "    # Perform the pca with the current number of clusters\n",
    "    k_centroids,k_labels = svq.kmeans2(data,k)\n",
    "    \n",
    "    # Get the stdev of each cluster's distances from the cluster's centroid\n",
    "    stdevs = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        \n",
    "        # Find the data points associated to the cluster\n",
    "        cluster_coords = data[k_labels==i,:]\n",
    "        \n",
    "        # Calculate the distance of these datapoints from the centroid\n",
    "        from scipy.spatial.distance import cdist\n",
    "        cluster_dists = cdist(cluster_coords,np.expand_dims(k_centroids[i],0))\n",
    "        \n",
    "        # Calculate the stdev of these distances\n",
    "        stdevs[i] = np.std(cluster_dists)\n",
    "    \n",
    "    # Average the stdevs for the different clusters\n",
    "    full_stdev = np.mean(stdevs)\n",
    "    \n",
    "    # Return the result\n",
    "    return full_stdev\n",
    "\n",
    "# Run for a range of cluster numbers\n",
    "test_k_list = range(1,13)\n",
    "k_stdevs = []\n",
    "np.random.seed(999) # See note 2 below\n",
    "for test_k in test_k_list:\n",
    "    k_stdevs.append(pca_stdev(fspace_pca,test_k))\n",
    "\n",
    "# Plot the elbow plot\n",
    "plt.plot(test_k_list,k_stdevs)\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Average Cluster STDEV\")\n",
    "plt.show()\n",
    "\n",
    "# Note 1: The resulting elbow plot is not particularly useful. The ideal outcome would be a plot\n",
    "#         with a clear 'elbow' (fast decay and then sudden bend into flat curve). In that case,\n",
    "#         one would choose the point near the 'elbow' as the ideal number of clusters. \n",
    "#         This result, however, makes it difficult to choose the number of clusters and probably\n",
    "#         indicates that this feature space cannot really be partitioned into sensible clusters, \n",
    "#         at least not with k-means. This is not unexpected, since we do not see separate \n",
    "#         populations when looking at the scatterplots of our features.\n",
    "#         For a nicer example of an elbow plot, see the result of the PCA in the section on\n",
    "#         \"Graph-Based Analysis\" below.\n",
    "\n",
    "# Note 2: The kmeans implementation used here is initialized with random centroid positions that \n",
    "#         are then optimized by the algorithm. Consequently, you will get a slightly different \n",
    "#         result each time you run the code. Here, I have ensured reproducibility by adding the\n",
    "#         line \"np.random.seed(999)\", which will ensure that the random number generator will \n",
    "#         produce the same starting positions each time.\n",
    "#         Furthermore, to make sure that you get a representative elbow plot, it would make sense \n",
    "#         to run the entire algorithm several times with different seeds and then use the average \n",
    "#         elbow plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE Analysis\n",
    "\n",
    "Although PCA is great to reduce and visualize high-dimensional data, it only\n",
    "works well on linear relationships and global trends. Therefore, alternative \n",
    "algorithms optimized for non-linear, local relationships have also been\n",
    "created.\n",
    "\n",
    "These algorithms tend to be quite complicated and going into them is beyond \n",
    "the scope of this tutorial. This example is intended as a taste of what is out\n",
    "there and to show people who already know about these methods that they are\n",
    "available in Python. Note that it can be risky to use these algorithms if \n",
    "you do not know what you are doing, so it may make sense to read up and/or to \n",
    "consult with an expert before you do this kind of analysis.\n",
    "\n",
    "This example uses the tSNE implementation in scikit-learn. tSNE (or t-distributed\n",
    "Stochastic Neighbor Embedding) is a machine learning algorithm that attempts to\n",
    "project the high-dimensional feature data into just 2 or 3 dimensions, preserving\n",
    "the proximity between samples as much as possible. In other words, samples that\n",
    "are close together in the full nD feature space should end up close together in\n",
    "the reduced 2D/3D feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tSNE with scikit-learn\n",
    "\n",
    "# As with the PCA, the first step is to instantiate an estimator object\n",
    "\n",
    "# Note 1: Here I enforce a dimensionality reduction to the 2 most important\n",
    "# components for illustration purposes. The same syntax could be used in the\n",
    "# skimage implementation of pca to do dimensionality reduction.\n",
    "\n",
    "# Note 2: random_state works much like numpy.random.seed.\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=999)\n",
    "\n",
    "# Fitting the data\n",
    "# Next, we fit thie estimator to our data and transform the data to the new\n",
    "# frame of reference. Here, this is done in one step directly.\n",
    "fspace_tsne = model.fit_transform(fspace_w)\n",
    "\n",
    "# Let's compare the result to the PCA\n",
    "fig,ax = plt.subplots(1,2,figsize=(7,3))\n",
    "\n",
    "ax[0].scatter(fspace_pca[:,0],fspace_pca[:,1],c=fspace_w[:,1])\n",
    "ax[0].set_title(\"PC1 vs PC2\")\n",
    "\n",
    "ax[1].scatter(fspace_tsne[:,0],fspace_tsne[:,1],c=fspace_w[:,1])\n",
    "ax[1].set_title(\"tSNE1 vs tSNE2\")\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Note: Once again, the data used here is too uniform to nicely illustrate\n",
    "#       how powerful tSNE is at finding structure in multi-dimensional data.\n",
    "#       The fact that all the points end up in a nice circle (except for\n",
    "#       some outliers) indicates that tSNE does not find any similarity-based\n",
    "#       structure in our feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph-Based Analysis\n",
    "\n",
    "Graphs are a universal way of mathematically describing relationships, be \n",
    "they based on similarity, interaction, or virtually anything else. Despite \n",
    "their power, graph-based analyses have so far not been used extensively on \n",
    "biological imaging data, but as microscopes and analysis algorithms improve,\n",
    "they become increasingly feasible and will likely become very important in\n",
    "the future.\n",
    "\n",
    "The `networkx` module provides various functions for importing and generating\n",
    "graphs, for operating on and analyzing graphs, and for exporting and visualizing\n",
    "graphs. The following example shows how a simple graph based on our feature \n",
    "space could be constructed and visualized. In doing so, it introduces the `networkx.Graph`\n",
    "object, which is the core of the `networkx` module.\n",
    "\n",
    "For this example, I am using the feature space generated by the DAISY descriptor,\n",
    "so I first need to clean it (remove outliers, standardize) and reduce its dimensionality, much\n",
    "as we did for the other feature space above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Outlier removal\n",
    "\n",
    "# Find outliers\n",
    "# Note: This approach removes many cells, and is thus likely not appropriate\n",
    "# for the DAISY features. However, I am keeping it for now since it does not\n",
    "# really matter for this data.\n",
    "stdevs = np.std(fspace2,axis=0)\n",
    "outliers = np.abs(fspace2-np.mean(fspace2,axis=0)) > 3 * stdevs\n",
    "\n",
    "# Remove outliers (whilst preserving mapping of fspace to labels)\n",
    "keep = np.where(np.sum(outliers,axis=1)==0)[0]\n",
    "labels2 = labels2[keep]\n",
    "fspace2 = fspace2[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardization\n",
    "fspace2_w = (fspace2 - np.mean(fspace2,axis=0)) / np.std(fspace2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimensionality reduction with PCA \n",
    "\n",
    "# Reduction to 50 components\n",
    "from sklearn.decomposition import PCA\n",
    "pca_estimator = PCA(n_components=50,copy=True)\n",
    "pca_estimator.fit(fspace2_w)    \n",
    "\n",
    "# Elbow plot of how much variance each PC explains\n",
    "plt.plot(range(1,51),pca_estimator.explained_variance_ratio_)\n",
    "plt.xlabel(\"PC\")\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.show()\n",
    "\n",
    "# Dimensionality reduction to 20 PCs\n",
    "# The choice of the number 20 is based on the elbow plot!\n",
    "pca_estimator = PCA(n_components=20,copy=True)\n",
    "pca_estimator.fit(fspace2_w)  \n",
    "fspace2_pca = pca_estimator.transform(fspace2_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construction of the Graph\n",
    "\n",
    "# As mentioned above, graphs are a very generic way of representing relations, so there are also\n",
    "# many ways of generating a graph. Here, I am thresholding the pairwise euclidean distance of the\n",
    "# cells after dimensionality reduction to 20 features by PCA.\n",
    "# In other words, I draw an edge between two nodes (cells) in the graph if they are sufficiently\n",
    "# close together in feature space. This graph thus represents relationships based on \"similarity\"\n",
    "# of the cells in feature space.\n",
    "# Computationally, a graph like this can be represented by an \"adjacency matrix\", a symmetric array\n",
    "# of shape (n_cells,n_cells) where 1 denotes an edge and 0 no edge between the cells of the \n",
    "# corresponding row and column.\n",
    "\n",
    "# Calculating pairwise distances\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "graph_pdists = squareform(pdist(fspace2_pca))\n",
    "\n",
    "# Thresholding pairwise distances\n",
    "# The threshold is chosen such that the closest 5% of cells will be connected.\n",
    "# The resulting array is the adjacency matrix of our graph.\n",
    "graph_thresh = graph_pdists <= np.percentile(graph_pdists,5)\n",
    "\n",
    "# Cleanup: Since the matrix is symmetric, remove one half of it (and the diagonal)\n",
    "graph_thresh = np.triu(graph_thresh,k=1)\n",
    "\n",
    "# Display the resulting adjacency matrix\n",
    "plt.imshow(graph_thresh,interpolation='none',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### From Adjacency Matrix to networkx Graph\n",
    "\n",
    "# This is pretty simple...\n",
    "import networkx as nx\n",
    "G = nx.from_numpy_matrix(graph_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Displaying the graph as a network\n",
    "\n",
    "# Once we have a networkx Graph object, there are many possibilities for \n",
    "# operating on, analyzing, partitioning and visualizing this graph. Here,  \n",
    "# I limit myself to showing some examples of visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display simple graph\n",
    "# Get node positions based on graph itself (force-based distribution) and colors from PC1\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "plt.figure(figsize=(7,7))\n",
    "nx.draw(G,pos=pos,cmap=plt.get_cmap('gist_rainbow'),node_color=fspace2_pca[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display simple graph\n",
    "# Get positions from PC1 and PC2 and colors from PC1\n",
    "pos_dict_pca = {}\n",
    "for index in range(len(labels2)):\n",
    "    pos_dict_pca[index] = fspace2_pca[index,:2]\n",
    "plt.figure(figsize=(7,7))\n",
    "nx.draw(G,pos=pos_dict_pca,cmap=plt.get_cmap('gist_rainbow'),node_color=fspace2_pca[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display graph nicely overlayed over cells and segmentation\n",
    "\n",
    "# Use cell centroids as node positions\n",
    "pos_dict_img = {}\n",
    "for index,label in enumerate(labels2):\n",
    "    cen_coords = ndi.measurements.center_of_mass(seg==label)\n",
    "    pos_dict_img[index] = (cen_coords[1],cen_coords[0])\n",
    "\n",
    "# Map PC1 onto the segmentation\n",
    "pca_mapped = np.zeros_like(seg)\n",
    "for index,label in enumerate(labels2):\n",
    "    pca_mapped[seg==label] = fspace2_pca[index,0]\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Plot image data\n",
    "plt.imshow(img_green,interpolation='none',cmap='gray')\n",
    "\n",
    "# Plot semi-transparent segmentation with PC1 coloring\n",
    "plt.imshow(np.ma.array(pca_mapped,mask=pca_mapped==0),\n",
    "           interpolation='none',cmap='winter',alpha=0.5)\n",
    "\n",
    "# Plot nodes on cells with PC1 coloring\n",
    "nx.draw_networkx_nodes(G,pos=pos_dict_img,\n",
    "                       cmap='winter',node_color=fspace2_pca[:,0],alpha=0.5,\n",
    "                       node_size=50,linewidths=0)\n",
    "\n",
    "# Plot edges\n",
    "nx.draw_networkx_edges(G,pos=pos_dict_img,\n",
    "                       edge_color='r',alpha=0.3)\n",
    "\n",
    "# nx.draw(G,pos=pos_dict_img,\n",
    "#         cmap=plt.get_cmap('gist_rainbow'),node_color=fspace2_pca[:,0],alpha=0.5,\n",
    "#         node_size=50,edge_color='0.5')\n",
    "\n",
    "# Done\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Note that graph visualization is not an easy task and the use of dedicated \n",
    "# software such as Cytoscape may be advisable on occasion. Networkx supports \n",
    "# the export of Graphs to various other software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>*Congratulations! You have completed the tutorial!*</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "**...but if you now just go back to your work and do nothing, you will forget all you learned within a month or two!**\n",
    "\n",
    "\n",
    "So, what to do?\n",
    "\n",
    "\n",
    "- Start applying what you have learned to your own work!\n",
    "\n",
    "\n",
    "- Stay engaged even if you currently don't need your new skills at work!\n",
    "\n",
    "    - Play around with data from your work, even if you don't need it at the moment\n",
    "\n",
    "    - Find yourself an interesting little 'pet project' to play around with\n",
    "\n",
    "    - Look for tutorials online with additional/advanced content\n",
    "    \n",
    "    - Join for seminars/events related to coding and image analysis\n",
    "        - Check out the [Bio-IT Portal](https://bio-it.embl.de/) for more info! *[internal access only]*\n",
    "        - Join the [EMBL Coding Club](https://bio-it.embl.de/coding-club/) *[internal access only]*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
